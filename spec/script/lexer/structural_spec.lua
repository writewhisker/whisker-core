-- spec/script/lexer/structural_spec.lua
-- Unit tests for structural token recognition

describe("Structural Tokens", function()
  local lexer_module

  before_each(function()
    -- Clear module cache
    for k in pairs(package.loaded) do
      if k:match("^whisker%.script") then
        package.loaded[k] = nil
      end
    end
    lexer_module = require("whisker.script.lexer")
  end)

  describe("Passage declaration (::)", function()
    it("should recognize ::", function()
      local stream = lexer_module.tokenize("::")
      assert.are.equal("PASSAGE_DECL", stream:advance().type)
    end)

    it("should recognize :: followed by identifier", function()
      local stream = lexer_module.tokenize(":: Start")
      assert.are.equal("PASSAGE_DECL", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)

    it("should preserve position for ::", function()
      local stream = lexer_module.tokenize("::")
      local token = stream:advance()
      assert.are.equal(1, token.pos.line)
      assert.are.equal(1, token.pos.column)
    end)

    it("should distinguish :: from single :", function()
      local stream = lexer_module.tokenize(": :")
      assert.are.equal("COLON", stream:advance().type)
      assert.are.equal("COLON", stream:advance().type)
    end)
  end)

  describe("Divert (->)", function()
    it("should recognize ->", function()
      local stream = lexer_module.tokenize("->")
      assert.are.equal("DIVERT", stream:advance().type)
    end)

    it("should recognize -> followed by identifier", function()
      local stream = lexer_module.tokenize("-> NextPassage")
      assert.are.equal("DIVERT", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)

    it("should have correct lexeme for ->", function()
      local stream = lexer_module.tokenize("->")
      assert.are.equal("->", stream:advance().lexeme)
    end)
  end)

  describe("Tunnel (->->)", function()
    it("should recognize ->->", function()
      local stream = lexer_module.tokenize("->->")
      assert.are.equal("TUNNEL", stream:advance().type)
    end)

    it("should distinguish ->-> from two ->", function()
      local stream = lexer_module.tokenize("->->")
      local token = stream:advance()
      assert.are.equal("TUNNEL", token.type)
      assert.are.equal("->->", token.lexeme)
      -- Should be EOF next, not another DIVERT
      assert.are.equal("EOF", stream:advance().type)
    end)

    it("should recognize tunnel followed by identifier", function()
      local stream = lexer_module.tokenize("->-> TunnelTarget")
      assert.are.equal("TUNNEL", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)

    it("should handle -> -> as two tokens", function()
      local stream = lexer_module.tokenize("-> ->")
      assert.are.equal("DIVERT", stream:advance().type)
      assert.are.equal("DIVERT", stream:advance().type)
    end)
  end)

  describe("Thread (<-)", function()
    it("should recognize <-", function()
      local stream = lexer_module.tokenize("<-")
      assert.are.equal("THREAD", stream:advance().type)
    end)

    it("should have correct lexeme for <-", function()
      local stream = lexer_module.tokenize("<-")
      assert.are.equal("<-", stream:advance().lexeme)
    end)

    it("should recognize thread followed by identifier", function()
      local stream = lexer_module.tokenize("<- ThreadName")
      assert.are.equal("THREAD", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)
  end)

  describe("Assignment (~)", function()
    it("should recognize ~", function()
      local stream = lexer_module.tokenize("~")
      assert.are.equal("ASSIGN", stream:advance().type)
    end)

    it("should recognize ~ in assignment context", function()
      local stream = lexer_module.tokenize("~ $x = 5")
      assert.are.equal("ASSIGN", stream:advance().type)
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("EQ", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
    end)
  end)

  describe("Metadata (@@)", function()
    it("should recognize @@", function()
      local stream = lexer_module.tokenize("@@")
      assert.are.equal("METADATA", stream:advance().type)
    end)

    it("should have correct lexeme for @@", function()
      local stream = lexer_module.tokenize("@@")
      assert.are.equal("@@", stream:advance().lexeme)
    end)

    it("should recognize @@ followed by identifier", function()
      local stream = lexer_module.tokenize("@@ author")
      assert.are.equal("METADATA", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)
  end)

  describe("Include (>>)", function()
    it("should recognize >>", function()
      local stream = lexer_module.tokenize(">>")
      assert.are.equal("INCLUDE", stream:advance().type)
    end)

    it("should have correct lexeme for >>", function()
      local stream = lexer_module.tokenize(">>")
      assert.are.equal(">>", stream:advance().lexeme)
    end)

    it("should distinguish >> from > >", function()
      local stream = lexer_module.tokenize("> >")
      assert.are.equal("GT", stream:advance().type)
      assert.are.equal("GT", stream:advance().type)
    end)

    it("should recognize >> followed by string", function()
      local stream = lexer_module.tokenize('>> "other.wsk"')
      assert.are.equal("INCLUDE", stream:advance().type)
      assert.are.equal("STRING", stream:advance().type)
    end)
  end)

  describe("Plus (+)", function()
    it("should recognize + as PLUS", function()
      local stream = lexer_module.tokenize("+")
      assert.are.equal("PLUS", stream:advance().type)
    end)

    it("should recognize += as compound assignment", function()
      local stream = lexer_module.tokenize("+=")
      assert.are.equal("PLUS_EQ", stream:advance().type)
    end)

    it("should recognize + in expression", function()
      local stream = lexer_module.tokenize("1 + 2")
      assert.are.equal("NUMBER", stream:advance().type)
      assert.are.equal("PLUS", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
    end)
  end)

  describe("Minus (-)", function()
    it("should recognize - as MINUS", function()
      local stream = lexer_module.tokenize("-")
      assert.are.equal("MINUS", stream:advance().type)
    end)

    it("should recognize -= as compound assignment", function()
      local stream = lexer_module.tokenize("-=")
      assert.are.equal("MINUS_EQ", stream:advance().type)
    end)

    it("should recognize - in expression", function()
      local stream = lexer_module.tokenize("5 - 3")
      assert.are.equal("NUMBER", stream:advance().type)
      assert.are.equal("MINUS", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
    end)
  end)

  describe("Colon (:)", function()
    it("should recognize single colon", function()
      local stream = lexer_module.tokenize(":")
      assert.are.equal("COLON", stream:advance().type)
    end)
  end)

  describe("Hash comments (#)", function()
    it("should recognize # comment", function()
      local stream = lexer_module.tokenize("# this is a comment")
      local token = stream:advance()
      assert.are.equal("COMMENT", token.type)
      assert.are.equal(" this is a comment", token.literal)
    end)

    it("should stop at newline", function()
      local stream = lexer_module.tokenize("# comment\nnext")
      assert.are.equal("COMMENT", stream:advance().type)
      assert.are.equal("NEWLINE", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)
  end)

  describe("Comparison operators", function()
    it("should recognize <", function()
      local stream = lexer_module.tokenize("<")
      assert.are.equal("LT", stream:advance().type)
    end)

    it("should recognize <=", function()
      local stream = lexer_module.tokenize("<=")
      assert.are.equal("LT_EQ", stream:advance().type)
    end)

    it("should recognize >", function()
      local stream = lexer_module.tokenize(">")
      assert.are.equal("GT", stream:advance().type)
    end)

    it("should recognize >=", function()
      local stream = lexer_module.tokenize(">=")
      assert.are.equal("GT_EQ", stream:advance().type)
    end)

    it("should recognize ==", function()
      local stream = lexer_module.tokenize("==")
      assert.are.equal("EQ_EQ", stream:advance().type)
    end)

    it("should recognize !=", function()
      local stream = lexer_module.tokenize("!=")
      assert.are.equal("BANG_EQ", stream:advance().type)
    end)

    it("should distinguish = from ==", function()
      local stream = lexer_module.tokenize("=")
      assert.are.equal("EQ", stream:advance().type)
    end)
  end)

  describe("Arithmetic operators", function()
    it("should recognize *", function()
      local stream = lexer_module.tokenize("*")
      assert.are.equal("STAR", stream:advance().type)
    end)

    it("should recognize *=", function()
      local stream = lexer_module.tokenize("*=")
      assert.are.equal("STAR_EQ", stream:advance().type)
    end)

    it("should recognize /", function()
      local stream = lexer_module.tokenize("/")
      assert.are.equal("SLASH", stream:advance().type)
    end)

    it("should recognize /=", function()
      local stream = lexer_module.tokenize("/=")
      assert.are.equal("SLASH_EQ", stream:advance().type)
    end)

    it("should recognize %", function()
      local stream = lexer_module.tokenize("%")
      assert.are.equal("PERCENT", stream:advance().type)
    end)
  end)

  describe("Logical operators", function()
    it("should recognize ! as NOT", function()
      local stream = lexer_module.tokenize("!")
      assert.are.equal("NOT", stream:advance().type)
    end)

    it("should distinguish ! from !=", function()
      local stream = lexer_module.tokenize("! !=")
      assert.are.equal("NOT", stream:advance().type)
      assert.are.equal("BANG_EQ", stream:advance().type)
    end)
  end)

  describe("Complex structural combinations", function()
    it("should handle passage with choices", function()
      local source = ":: Start\n+ Choice A\n+ Choice B"
      local stream = lexer_module.tokenize(source)
      assert.are.equal("PASSAGE_DECL", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)  -- Start
      assert.are.equal("NEWLINE", stream:advance().type)
      assert.are.equal("PLUS", stream:advance().type)
    end)

    it("should handle passage with divert", function()
      local stream = lexer_module.tokenize(":: Start\n-> End")
      assert.are.equal("PASSAGE_DECL", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
      assert.are.equal("NEWLINE", stream:advance().type)
      assert.are.equal("DIVERT", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)

    it("should handle assignment with comparison", function()
      local stream = lexer_module.tokenize("~ $x = $y == 5")
      assert.are.equal("ASSIGN", stream:advance().type)
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("EQ", stream:advance().type)
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("EQ_EQ", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
    end)
  end)
end)
