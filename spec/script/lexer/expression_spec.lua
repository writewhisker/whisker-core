-- spec/script/lexer/expression_spec.lua
-- Unit tests for expression token recognition

describe("Expression Tokens", function()
  local lexer_module

  before_each(function()
    -- Clear module cache
    for k in pairs(package.loaded) do
      if k:match("^whisker%.script") then
        package.loaded[k] = nil
      end
    end
    lexer_module = require("whisker.script.lexer")
  end)

  describe("Number literals", function()
    it("should parse integer zero", function()
      local stream = lexer_module.tokenize("0")
      local token = stream:advance()
      assert.are.equal("NUMBER", token.type)
      assert.are.equal("0", token.lexeme)
      assert.are.equal(0, token.literal)
    end)

    it("should parse single digit integer", function()
      local stream = lexer_module.tokenize("7")
      local token = stream:advance()
      assert.are.equal("NUMBER", token.type)
      assert.are.equal(7, token.literal)
    end)

    it("should parse multi-digit integer", function()
      local stream = lexer_module.tokenize("42")
      local token = stream:advance()
      assert.are.equal("NUMBER", token.type)
      assert.are.equal("42", token.lexeme)
      assert.are.equal(42, token.literal)
    end)

    it("should parse large integer", function()
      local stream = lexer_module.tokenize("123456789")
      local token = stream:advance()
      assert.are.equal("NUMBER", token.type)
      assert.are.equal(123456789, token.literal)
    end)

    it("should parse decimal number", function()
      local stream = lexer_module.tokenize("3.14")
      local token = stream:advance()
      assert.are.equal("NUMBER", token.type)
      assert.are.equal("3.14", token.lexeme)
      assert.are.equal(3.14, token.literal)
    end)

    it("should parse decimal with leading zero", function()
      local stream = lexer_module.tokenize("0.5")
      local token = stream:advance()
      assert.are.equal("NUMBER", token.type)
      assert.are.equal(0.5, token.literal)
    end)

    it("should parse decimal with many places", function()
      local stream = lexer_module.tokenize("3.14159")
      local token = stream:advance()
      assert.are.equal("NUMBER", token.type)
      assert.are.equal(3.14159, token.literal)
    end)

    it("should handle integer followed by dot and non-digit", function()
      local stream = lexer_module.tokenize("5.x")
      local token = stream:advance()
      assert.are.equal("NUMBER", token.type)
      assert.are.equal(5, token.literal)
    end)

    it("should handle number in expression", function()
      local stream = lexer_module.tokenize("1 + 2")
      assert.are.equal(1, stream:advance().literal)
      assert.are.equal("PLUS", stream:advance().type)
      assert.are.equal(2, stream:advance().literal)
    end)
  end)

  describe("String literals", function()
    it("should parse empty string", function()
      local stream = lexer_module.tokenize('""')
      local token = stream:advance()
      assert.are.equal("STRING", token.type)
      assert.are.equal("", token.literal)
    end)

    it("should parse simple string", function()
      local stream = lexer_module.tokenize('"hello"')
      local token = stream:advance()
      assert.are.equal("STRING", token.type)
      assert.are.equal("hello", token.literal)
    end)

    it("should parse string with spaces", function()
      local stream = lexer_module.tokenize('"hello world"')
      local token = stream:advance()
      assert.are.equal("STRING", token.type)
      assert.are.equal("hello world", token.literal)
    end)

    it("should handle escaped newline", function()
      local stream = lexer_module.tokenize('"line1\\nline2"')
      local token = stream:advance()
      assert.are.equal("STRING", token.type)
      assert.are.equal("line1\nline2", token.literal)
    end)

    it("should handle escaped tab", function()
      local stream = lexer_module.tokenize('"a\\tb"')
      local token = stream:advance()
      assert.are.equal("a\tb", token.literal)
    end)

    it("should handle escaped backslash", function()
      local stream = lexer_module.tokenize('"a\\\\b"')
      local token = stream:advance()
      assert.are.equal("a\\b", token.literal)
    end)

    it("should handle escaped quote", function()
      local stream = lexer_module.tokenize('"say \\"hi\\""')
      local token = stream:advance()
      assert.are.equal('say "hi"', token.literal)
    end)

    it("should parse single-quoted string", function()
      local stream = lexer_module.tokenize("'hello'")
      local token = stream:advance()
      assert.are.equal("STRING", token.type)
      assert.are.equal("hello", token.literal)
    end)

    it("should preserve lexeme with quotes", function()
      local stream = lexer_module.tokenize('"test"')
      local token = stream:advance()
      assert.are.equal('"test"', token.lexeme)
    end)

    it("should report unterminated string", function()
      local stream = lexer_module.tokenize('"unterminated')
      local token = stream:advance()
      assert.are.equal("ERROR", token.type)
    end)

    it("should report unterminated string at newline", function()
      local stream = lexer_module.tokenize('"broken\nstring"')
      local token = stream:advance()
      assert.are.equal("ERROR", token.type)
    end)
  end)

  describe("Identifiers", function()
    it("should parse simple identifier", function()
      local stream = lexer_module.tokenize("foo")
      local token = stream:advance()
      assert.are.equal("IDENTIFIER", token.type)
      assert.are.equal("foo", token.lexeme)
    end)

    it("should parse identifier with underscore", function()
      local stream = lexer_module.tokenize("my_var")
      local token = stream:advance()
      assert.are.equal("IDENTIFIER", token.type)
      assert.are.equal("my_var", token.lexeme)
    end)

    it("should parse identifier starting with underscore", function()
      local stream = lexer_module.tokenize("_private")
      local token = stream:advance()
      assert.are.equal("IDENTIFIER", token.type)
      assert.are.equal("_private", token.lexeme)
    end)

    it("should parse identifier with digits", function()
      local stream = lexer_module.tokenize("var123")
      local token = stream:advance()
      assert.are.equal("IDENTIFIER", token.type)
      assert.are.equal("var123", token.lexeme)
    end)

    it("should parse camelCase identifier", function()
      local stream = lexer_module.tokenize("myVariableName")
      local token = stream:advance()
      assert.are.equal("IDENTIFIER", token.type)
      assert.are.equal("myVariableName", token.lexeme)
    end)

    it("should not confuse identifier starting with keyword", function()
      local stream = lexer_module.tokenize("android")
      local token = stream:advance()
      assert.are.equal("IDENTIFIER", token.type)
      assert.are.equal("android", token.lexeme)
    end)
  end)

  describe("Keywords", function()
    it("should recognize 'and'", function()
      local stream = lexer_module.tokenize("and")
      assert.are.equal("AND", stream:advance().type)
    end)

    it("should recognize 'or'", function()
      local stream = lexer_module.tokenize("or")
      assert.are.equal("OR", stream:advance().type)
    end)

    it("should recognize 'not'", function()
      local stream = lexer_module.tokenize("not")
      assert.are.equal("NOT", stream:advance().type)
    end)

    it("should recognize 'true'", function()
      local stream = lexer_module.tokenize("true")
      assert.are.equal("TRUE", stream:advance().type)
    end)

    it("should recognize 'false'", function()
      local stream = lexer_module.tokenize("false")
      assert.are.equal("FALSE", stream:advance().type)
    end)

    it("should recognize 'null'", function()
      local stream = lexer_module.tokenize("null")
      assert.are.equal("NULL", stream:advance().type)
    end)

    it("should recognize 'else'", function()
      local stream = lexer_module.tokenize("else")
      assert.are.equal("ELSE", stream:advance().type)
    end)

    it("should recognize 'if'", function()
      local stream = lexer_module.tokenize("if")
      assert.are.equal("IF", stream:advance().type)
    end)

    it("should recognize 'elif'", function()
      local stream = lexer_module.tokenize("elif")
      assert.are.equal("ELIF", stream:advance().type)
    end)

    it("should recognize 'include'", function()
      local stream = lexer_module.tokenize("include")
      assert.are.equal("INCLUDE_KW", stream:advance().type)
    end)

    it("should recognize 'import'", function()
      local stream = lexer_module.tokenize("import")
      assert.are.equal("IMPORT_KW", stream:advance().type)
    end)

    it("should recognize 'as'", function()
      local stream = lexer_module.tokenize("as")
      assert.are.equal("AS", stream:advance().type)
    end)

    it("should be case sensitive", function()
      local stream = lexer_module.tokenize("AND")
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)
  end)

  describe("Variable references", function()
    it("should parse simple variable", function()
      local stream = lexer_module.tokenize("$x")
      local token = stream:advance()
      assert.are.equal("VARIABLE", token.type)
      assert.are.equal("$x", token.lexeme)
      assert.are.equal("x", token.literal)
    end)

    it("should parse variable with underscore", function()
      local stream = lexer_module.tokenize("$my_var")
      local token = stream:advance()
      assert.are.equal("VARIABLE", token.type)
      assert.are.equal("my_var", token.literal)
    end)

    it("should parse variable with digits", function()
      local stream = lexer_module.tokenize("$var123")
      local token = stream:advance()
      assert.are.equal("VARIABLE", token.type)
      assert.are.equal("var123", token.literal)
    end)

    it("should error on $ without identifier", function()
      local stream = lexer_module.tokenize("$ ")
      local token = stream:advance()
      assert.are.equal("ERROR", token.type)
    end)

    it("should error on $ with digit start", function()
      local stream = lexer_module.tokenize("$123")
      local token = stream:advance()
      assert.are.equal("ERROR", token.type)
    end)
  end)

  describe("Arithmetic operators", function()
    it("should recognize +", function()
      local stream = lexer_module.tokenize("+")
      assert.are.equal("PLUS", stream:advance().type)
    end)

    it("should recognize -", function()
      local stream = lexer_module.tokenize("-")
      assert.are.equal("MINUS", stream:advance().type)
    end)

    it("should recognize *", function()
      local stream = lexer_module.tokenize("*")
      assert.are.equal("STAR", stream:advance().type)
    end)

    it("should recognize /", function()
      local stream = lexer_module.tokenize("/")
      assert.are.equal("SLASH", stream:advance().type)
    end)

    it("should recognize %", function()
      local stream = lexer_module.tokenize("%")
      assert.are.equal("PERCENT", stream:advance().type)
    end)

    it("should handle arithmetic expression", function()
      local stream = lexer_module.tokenize("a + b * c")
      assert.are.equal("IDENTIFIER", stream:advance().type)
      assert.are.equal("PLUS", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
      assert.are.equal("STAR", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
    end)
  end)

  describe("Comparison operators", function()
    it("should recognize ==", function()
      local stream = lexer_module.tokenize("==")
      assert.are.equal("EQ_EQ", stream:advance().type)
    end)

    it("should recognize !=", function()
      local stream = lexer_module.tokenize("!=")
      assert.are.equal("BANG_EQ", stream:advance().type)
    end)

    it("should recognize <", function()
      local stream = lexer_module.tokenize("<")
      assert.are.equal("LT", stream:advance().type)
    end)

    it("should recognize >", function()
      local stream = lexer_module.tokenize(">")
      assert.are.equal("GT", stream:advance().type)
    end)

    it("should recognize <=", function()
      local stream = lexer_module.tokenize("<=")
      assert.are.equal("LT_EQ", stream:advance().type)
    end)

    it("should recognize >=", function()
      local stream = lexer_module.tokenize(">=")
      assert.are.equal("GT_EQ", stream:advance().type)
    end)

    it("should handle comparison expression", function()
      local stream = lexer_module.tokenize("$x >= 10")
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("GT_EQ", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
    end)
  end)

  describe("Assignment operators", function()
    it("should recognize =", function()
      local stream = lexer_module.tokenize("=")
      assert.are.equal("EQ", stream:advance().type)
    end)

    it("should recognize +=", function()
      local stream = lexer_module.tokenize("+=")
      assert.are.equal("PLUS_EQ", stream:advance().type)
    end)

    it("should recognize -=", function()
      local stream = lexer_module.tokenize("-=")
      assert.are.equal("MINUS_EQ", stream:advance().type)
    end)

    it("should recognize *=", function()
      local stream = lexer_module.tokenize("*=")
      assert.are.equal("STAR_EQ", stream:advance().type)
    end)

    it("should recognize /=", function()
      local stream = lexer_module.tokenize("/=")
      assert.are.equal("SLASH_EQ", stream:advance().type)
    end)

    it("should handle compound assignment", function()
      local stream = lexer_module.tokenize("$x += 5")
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("PLUS_EQ", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
    end)
  end)

  describe("Delimiters", function()
    it("should recognize {", function()
      local stream = lexer_module.tokenize("{")
      assert.are.equal("LBRACE", stream:advance().type)
    end)

    it("should recognize }", function()
      local stream = lexer_module.tokenize("}")
      assert.are.equal("RBRACE", stream:advance().type)
    end)

    it("should recognize [", function()
      local stream = lexer_module.tokenize("[")
      assert.are.equal("LBRACKET", stream:advance().type)
    end)

    it("should recognize ]", function()
      local stream = lexer_module.tokenize("]")
      assert.are.equal("RBRACKET", stream:advance().type)
    end)

    it("should recognize (", function()
      local stream = lexer_module.tokenize("(")
      assert.are.equal("LPAREN", stream:advance().type)
    end)

    it("should recognize )", function()
      local stream = lexer_module.tokenize(")")
      assert.are.equal("RPAREN", stream:advance().type)
    end)

    it("should recognize :", function()
      local stream = lexer_module.tokenize(":")
      assert.are.equal("COLON", stream:advance().type)
    end)

    it("should recognize |", function()
      local stream = lexer_module.tokenize("|")
      assert.are.equal("PIPE", stream:advance().type)
    end)

    it("should recognize ,", function()
      local stream = lexer_module.tokenize(",")
      assert.are.equal("COMMA", stream:advance().type)
    end)

    it("should recognize .", function()
      local stream = lexer_module.tokenize(".")
      assert.are.equal("DOT", stream:advance().type)
    end)

    it("should handle grouped expression", function()
      local stream = lexer_module.tokenize("(a + b)")
      assert.are.equal("LPAREN", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
      assert.are.equal("PLUS", stream:advance().type)
      assert.are.equal("IDENTIFIER", stream:advance().type)
      assert.are.equal("RPAREN", stream:advance().type)
    end)
  end)

  describe("Complex expressions", function()
    it("should tokenize boolean expression", function()
      local stream = lexer_module.tokenize("$x and $y or not $z")
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("AND", stream:advance().type)
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("OR", stream:advance().type)
      assert.are.equal("NOT", stream:advance().type)
      assert.are.equal("VARIABLE", stream:advance().type)
    end)

    it("should tokenize conditional expression", function()
      local stream = lexer_module.tokenize("$score >= 100 and $level == 5")
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("GT_EQ", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
      assert.are.equal("AND", stream:advance().type)
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("EQ_EQ", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
    end)

    it("should tokenize string comparison", function()
      local stream = lexer_module.tokenize('$name == "Alice"')
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("EQ_EQ", stream:advance().type)
      assert.are.equal("STRING", stream:advance().type)
    end)

    it("should tokenize inline expression with braces", function()
      local stream = lexer_module.tokenize("{$x + 1}")
      assert.are.equal("LBRACE", stream:advance().type)
      assert.are.equal("VARIABLE", stream:advance().type)
      assert.are.equal("PLUS", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
      assert.are.equal("RBRACE", stream:advance().type)
    end)

    it("should tokenize function-like call", function()
      local stream = lexer_module.tokenize("random(1, 10)")
      assert.are.equal("IDENTIFIER", stream:advance().type)
      assert.are.equal("LPAREN", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
      assert.are.equal("COMMA", stream:advance().type)
      assert.are.equal("NUMBER", stream:advance().type)
      assert.are.equal("RPAREN", stream:advance().type)
    end)
  end)

  describe("Position tracking in expressions", function()
    it("should track position for each token", function()
      local stream = lexer_module.tokenize("a + b")
      local a = stream:advance()
      local plus = stream:advance()
      local b = stream:advance()

      assert.are.equal(1, a.pos.column)
      assert.are.equal(3, plus.pos.column)
      assert.are.equal(5, b.pos.column)
    end)

    it("should track line for multiline expression", function()
      local stream = lexer_module.tokenize("a +\nb")
      stream:advance()  -- a
      stream:advance()  -- +
      stream:advance()  -- NEWLINE
      local b = stream:advance()  -- b
      assert.are.equal(2, b.pos.line)
    end)
  end)
end)
